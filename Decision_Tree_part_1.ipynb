{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree   \n",
        "\n",
        "Decision Tree is a machine learning model that makes decisions by asking simple questions step-by-step, like a flowchart.\n",
        "\n",
        "# Pseudo Code\n",
        "\n",
        "Point 1:\n",
        "\n",
        "Begin with your training dataset, which should have some feature variables and classification or regression output.\n",
        "\n",
        "Point 2:\n",
        "\n",
        "Determine the “best feature” in the dataset to split the data on\n",
        "\n",
        "Point 3:\n",
        "\n",
        "Split the data into subsets that contain the correct values for this best feature.\n",
        "\n",
        "Point 4:\n",
        "\n",
        "Recursively generate new tree nodes by using the subset of data created from step 3.\n"
      ],
      "metadata": {
        "id": "QUzjbAITVjJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advantages\n",
        "\n",
        "Very Easy to Understand\n",
        "\n",
        "No Need for Data Scaling\n",
        "\n",
        "Works on Both Types of Data  (Numerical and Categorical)\n",
        "\n",
        "Handles Non-Linear Data Well\n",
        "\n",
        "Feature Selection Automatically\n",
        "\n",
        "Can Solve Both Problems\n",
        "\n"
      ],
      "metadata": {
        "id": "GzVyrysCXYTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disadvantages\n",
        "\n",
        "Overfitting (Biggest Problem)\n",
        "\n",
        "Unstable Model\n",
        "\n",
        "Less Accurate Than Ensemble Models\n",
        "\n",
        "Can Become Very Complex\n",
        "\n",
        "Biased Toward Dominant Features\n"
      ],
      "metadata": {
        "id": "RkX3LUcRXpq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy\n",
        "\n",
        "Measure of Disorder / Impurity in data\n",
        "\n",
        "It tells how mixed or pure your data is.\n",
        "\n",
        "\n",
        "More uncertainty more is entropy\n"
      ],
      "metadata": {
        "id": "dV3HqAf0Y2u2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvpSHBJ6RH9e"
      },
      "outputs": [],
      "source": [
        "# How to calculate Entropy ?\n",
        "\n",
        "Entropy=−∑plog2​(p)\n",
        "\n",
        "p = probability of each class (0 or 1)\n",
        "\n",
        "other form\n",
        "\n",
        "Entropy=−(plog2​(p)+(1−p)log2​(1−p))\n",
        "\n",
        "p = probability of class 1\n",
        "\n",
        "1−p = probability of class 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Gain\n",
        "\n",
        "How much uncertainty (entropy) is reduced after a split.\n",
        "\n",
        "The tree always chooses:\n",
        "\n",
        "The split with the HIGHEST Information Gain"
      ],
      "metadata": {
        "id": "GUQlQIrebUAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Formula\n",
        "\n",
        "Information Gain=Entropy(parent)−Entropy(after split)\n",
        "\n",
        "Very simple logic:\n",
        "\n",
        "Before split → More confusion\n",
        "\n",
        "After split → Less confusion\n",
        "\n",
        "Difference = Information Gain"
      ],
      "metadata": {
        "id": "ApJMer1jbfDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gini Impurity\n",
        "\n",
        "It measures how impure or messy the data is after a split.\n",
        "\n",
        "# Formula\n",
        "\n",
        "Gini=1−∑pi2​\n",
        "\n",
        "pi = probability of each class\n",
        "\n",
        "# If only two classes:\n",
        "\n",
        "Gini=1−(p2+(1−p)2)\n",
        "\n",
        "p = probability of class 1\n",
        "\n",
        "1−p = probability of class 0\n",
        "\n"
      ],
      "metadata": {
        "id": "oA3HwHsqcg0l"
      }
    }
  ]
}